{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS/CMPSC 410 Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/icds/RISE/sw8/anaconda/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#What I’m doing here is basically importing all the PySpark components I need for this project.\n",
    "#I load Spark SQL, ML, and some feature engineering tools, plus the classifier and evaluator.\n",
    "#This is just the standard setup before I can run any Spark pipeline.\n",
    "\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/storage/home/yfl5682/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/storage/home/yfl5682/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "25/12/04 17:44:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/04 17:44:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Here I’m just creating the Spark session\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"DS410_TimeSeries_Tweets\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Disable ANSI mode so malformed values become NULL instead of killing the job\n",
    "spark.conf.set(\"spark.sql.ansi.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the file we need for the pipeline and ml\n",
    "\n",
    "spx_path = \"/storage/work/yfl5682/Project/SP500/SPX_full_5min_with_datetime_parts.csv\"\n",
    "tweets_path = \"/storage/work/yfl5682/Project/tweets_with_topics_v2_flat.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPX rows: 357535\n",
      "+-------------------+-------+-------+-------+-------+\n",
      "|bar_time           |Open   |High   |Low    |Close  |\n",
      "+-------------------+-------+-------+-------+-------+\n",
      "|2008-01-02 09:30:00|1467.97|1470.14|1467.97|1470.05|\n",
      "|2008-01-02 09:35:00|1470.17|1470.17|1467.88|1469.49|\n",
      "|2008-01-02 09:40:00|1469.78|1471.71|1469.39|1471.22|\n",
      "|2008-01-02 09:45:00|1471.56|1471.77|1470.69|1470.78|\n",
      "|2008-01-02 09:50:00|1470.28|1471.06|1470.1 |1470.74|\n",
      "+-------------------+-------+-------+-------+-------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------------------+--------------------+\n",
      "|           bar_time|  Close|          rv_pre_30m|         rv_post_30m|\n",
      "+-------------------+-------+--------------------+--------------------+\n",
      "|2008-01-02 09:30:00|1470.05|                NULL|0.004660684218949346|\n",
      "|2008-01-02 09:35:00|1469.49|                NULL|0.004714627426470183|\n",
      "|2008-01-02 09:40:00|1471.22|3.810119996833424E-4|0.004947337820406521|\n",
      "|2008-01-02 09:45:00|1470.78|0.001236740274360...|0.004863112334274586|\n",
      "|2008-01-02 09:50:00|1470.74|0.001272398144075946|0.004897381750463964|\n",
      "+-------------------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PART A. Load SPX data, build bar_time, compute RV\n",
    "# ==================================================\n",
    "\n",
    "# In this cell what I’m basically doing is preparing the SPX 5-minute time series\n",
    "# and building the volatility labels I’ll later join with Trump tweets.\n",
    "\n",
    "# I read in the SPX CSV that already has year/month/day/hour/minute/second\n",
    "# split out as separate columns. Then I cast all of these time parts and the OHLC(Open, High, Low, Close), check SP 500 file \n",
    "# price fields into the correct numeric types so Spark can do proper math on them.\n",
    "\n",
    "# I then reconstruct a full timestamp column called bar_time by stitching\n",
    "# together the year/month/day/hour/minute/second into a single string and then\n",
    "# converting it to a real Spark timestamp. This gives me a clean time index for\n",
    "# each 5-minute bar. if you guys want to use 1 minute bar it will be still very simple. \n",
    "\n",
    "# Once I have bar_time, I compute log returns of the SPX close price\n",
    "# within each trading day using a window ordered by time. then I build\n",
    "# realized volatility features, 30-minute pre-event RV, using the previous 6 bars;\n",
    "# and 30-minute post-event RV, using the current bar plus the next 6 bars.\n",
    "# These two columns: `rv_pre_30m` and `rv_post_30m`, will later serve as my\n",
    "# “before vs after tweet” volatility measures.\n",
    "\n",
    "\n",
    "\n",
    "# 2.1 Read SPX CSV (5-min bars with datetime parts)\n",
    "spx_raw = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(spx_path)\n",
    ")\n",
    "\n",
    "# 2.2 Cast numeric fields to proper types\n",
    "spx = (\n",
    "    spx_raw\n",
    "    .withColumn(\"year\",   F.col(\"year\").cast(T.IntegerType()))\n",
    "    .withColumn(\"month\",  F.col(\"month\").cast(T.IntegerType()))\n",
    "    .withColumn(\"day\",    F.col(\"day\").cast(T.IntegerType()))\n",
    "    .withColumn(\"hour\",   F.col(\"hour\").cast(T.IntegerType()))\n",
    "    .withColumn(\"minute\", F.col(\"minute\").cast(T.IntegerType()))\n",
    "    .withColumn(\"second\", F.col(\"second\").cast(T.IntegerType()))\n",
    "    .withColumn(\"Open\",   F.col(\"Open\").cast(T.DoubleType()))\n",
    "    .withColumn(\"High\",   F.col(\"High\").cast(T.DoubleType()))\n",
    "    .withColumn(\"Low\",    F.col(\"Low\").cast(T.DoubleType()))\n",
    "    .withColumn(\"Close\",  F.col(\"Close\").cast(T.DoubleType()))\n",
    ")\n",
    "\n",
    "# 2.3 Reconstruct full timestamp for each bar\n",
    "spx_time_str = F.format_string(\n",
    "    \"%04d-%02d-%02d %02d:%02d:%02d\",\n",
    "    F.col(\"year\"), F.col(\"month\"), F.col(\"day\"),\n",
    "    F.col(\"hour\"), F.col(\"minute\"), F.col(\"second\")\n",
    ")\n",
    "\n",
    "spx = spx.withColumn(\n",
    "    \"bar_time\",\n",
    "    F.to_timestamp(spx_time_str, \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "\n",
    "print(\"SPX rows:\", spx.count())\n",
    "spx.select(\"bar_time\", \"Open\", \"High\", \"Low\", \"Close\").show(5, truncate=False)\n",
    "\n",
    "# 2.4 Compute log returns and 30-min pre/post realized volatility\n",
    "# Use a per-day window to avoid unnecessary full-table windows\n",
    "w_order = Window.partitionBy(F.to_date(\"bar_time\")).orderBy(\"bar_time\")\n",
    "\n",
    "spx_lr = spx.withColumn(\n",
    "    \"log_return\",\n",
    "    F.log(F.col(\"Close\") / F.lag(\"Close\").over(w_order))\n",
    ")\n",
    "\n",
    "# 6 previous / next bars = 30 minutes for 5-min data\n",
    "w_pre = w_order.rowsBetween(-6, -1)\n",
    "w_post = w_order.rowsBetween(0, 6)\n",
    "\n",
    "spx_rv = (\n",
    "    spx_lr\n",
    "    .withColumn(\n",
    "        \"rv_pre_30m\",\n",
    "        F.sqrt(F.sum(F.pow(F.col(\"log_return\"), F.lit(2.0))).over(w_pre))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"rv_post_30m\",\n",
    "        F.sqrt(F.sum(F.pow(F.col(\"log_return\"), F.lit(2.0))).over(w_post))\n",
    "    )\n",
    ")\n",
    "\n",
    "spx_rv.select(\"bar_time\", \"Close\", \"rv_pre_30m\", \"rv_post_30m\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------------------------------+-----------------------------------------------------------------+---------+---------+--------------------+---------+--------+--------+----------+\n",
      "|                 id|         tweet_time|                               category|                                                    blue_category|sentiment|intensity|during_trading_hours|favorites|retweets|text_len|num_exclam|\n",
      "+-------------------+-------------------+---------------------------------------+-----------------------------------------------------------------+---------+---------+--------------------+---------+--------+--------+----------+\n",
      "|  98454970654916608|2011-08-02 18:07:48|     Macroeconomics & Monetary Policies|                                          Market / Economy / Jobs| Negative|   Medium|               False|       49|     255|      66|         0|\n",
      "|1234653427789070336|2020-03-03 01:34:50|   Campaign / Rally / Election Politics|             Campaign / Elections / Rallies / Political Messaging| Positive|     High|               False|    73748|   17404|     255|         3|\n",
      "|1304875170860015617|2020-09-12 20:10:58|   Campaign / Rally / Election Politics|             Campaign / Elections / Rallies / Political Messaging| Negative|     High|               False|    80527|   23502|     289|         1|\n",
      "|1223640662689689602|2020-02-01 16:14:02|Personal, Social, or Non-Policy Content|Personal / Social / Non-Policy Content (Congrats, Holidays, Misc)| Positive|      Low|               False|   285863|   30209|      39|         1|\n",
      "|1215247978966986752|2020-01-09 12:24:31|Personal, Social, or Non-Policy Content|Personal / Social / Non-Policy Content (Congrats, Holidays, Misc)| Positive|      Low|                True|    48510|   11608|      16|         1|\n",
      "+-------------------+-------------------+---------------------------------------+-----------------------------------------------------------------+---------+---------+--------------------+---------+--------+--------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PART B. Load tweets, build tweet_time, basic features\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "\n",
    "# here what im trying to do is to rebuild a clean timestamp for each tweet, and engineer a few simple\n",
    "# features that I might use later in the ML pipeline.\n",
    "\n",
    "# I cast all the time-related columns plus favorites and retweets\n",
    "# into integers, and I drop any rows where the datetime pieces are incomplete.\n",
    "# I don’t want broken timestamps to mess up the time alignment with SPX.\n",
    "#\n",
    "# I reconstruct a full `tweet_time` timestamp column, similar to what\n",
    "# I did for SPX, by formatting year/month/day/hour/minute/second into a\n",
    "# single string and converting it to a Spark timestamp.\n",
    "#\n",
    "# I clean up the boolean flags `isRetweet` and `isDeleted` by turning\n",
    "# the original \"t\"/\"f\" strings into real Boolean columns. I’m not necessarily\n",
    "# using them in the main ML model yet, but I keep them in a clean format. Highly doubt that if this is even useful lmao...\n",
    "#\n",
    "# I build some super simple text-based features: length of the tweet\n",
    "# (`text_len`) and how many exclamation marks it has (`num_exclam`). At the\n",
    "# end I preview the key columns I care about: timing, topic labels, sentiment,\n",
    "# trading-hours flag, engagement metrics, and the basic text features. you guys could add more interesting features if u want. \n",
    "\n",
    "\n",
    "# 3.1 Read flat tweets CSV\n",
    "tweets_raw = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(tweets_path)\n",
    ")\n",
    "\n",
    "# 3.2 Cast integer columns\n",
    "int_cols = [\n",
    "    \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\",\n",
    "    \"favorites\", \"retweets\"\n",
    "]\n",
    "\n",
    "tweets_num = tweets_raw\n",
    "for c in int_cols:\n",
    "    tweets_num = tweets_num.withColumn(c, F.col(c).cast(T.IntegerType()))\n",
    "\n",
    "# Drop rows with incomplete datetime fields\n",
    "tweets_num = tweets_num.filter(\n",
    "    F.col(\"year\").isNotNull() &\n",
    "    F.col(\"month\").isNotNull() &\n",
    "    F.col(\"day\").isNotNull() &\n",
    "    F.col(\"hour\").isNotNull() &\n",
    "    F.col(\"minute\").isNotNull() &\n",
    "    F.col(\"second\").isNotNull()\n",
    ")\n",
    "\n",
    "# 3.3 Build full tweet timestamp\n",
    "tweet_time_str = F.format_string(\n",
    "    \"%04d-%02d-%02d %02d:%02d:%02d\",\n",
    "    F.col(\"year\"), F.col(\"month\"), F.col(\"day\"),\n",
    "    F.col(\"hour\"), F.col(\"minute\"), F.col(\"second\")\n",
    ")\n",
    "\n",
    "tweets = tweets_num.withColumn(\n",
    "    \"tweet_time\",\n",
    "    F.to_timestamp(tweet_time_str, \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "\n",
    "# 3.4 Boolean flags (we do not use them in ML, but keep them clean)\n",
    "tweets = (\n",
    "    tweets\n",
    "    .withColumn(\"isRetweet\", (F.col(\"isRetweet\") == F.lit(\"t\")).cast(T.BooleanType()))\n",
    "    .withColumn(\"isDeleted\", (F.col(\"isDeleted\") == F.lit(\"t\")).cast(T.BooleanType()))\n",
    ")\n",
    "\n",
    "# 3.5 Simple text features\n",
    "tweets = (\n",
    "    tweets\n",
    "    .withColumn(\"text_len\",   F.length(\"text\"))\n",
    "    .withColumn(\"num_exclam\", F.size(F.split(F.col(\"text\"), \"!\")) - F.lit(1))\n",
    ")\n",
    "\n",
    "tweets.select(\n",
    "    \"id\", \"tweet_time\", \"category\", \"blue_category\",\n",
    "    \"sentiment\", \"intensity\", \"during_trading_hours\",\n",
    "    \"favorites\", \"retweets\", \"text_len\", \"num_exclam\"\n",
    ").show(5, truncate=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events rows (tweets used in pipeline): 10870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------+---------------------+---------------------+----------+----------+--------+--------+\n",
      "|id                 |tweet_time         |event_time         |Close  |rv_pre_30m           |rv_post_30m          |tweet_year|tweet_hour|spx_year|spx_hour|\n",
      "+-------------------+-------------------+-------------------+-------+---------------------+---------------------+----------+----------+--------+--------+\n",
      "|1001404640796336128|2018-05-29 10:07:26|2018-05-29 10:05:00|2709.29|0.0019230080247938965|0.0018386673426389981|2018      |10        |2018    |10      |\n",
      "|1001410457092218880|2018-05-29 10:30:32|2018-05-29 10:30:00|2704.19|0.0012550933708381099|0.0023081077350491125|2018      |10        |2018    |10      |\n",
      "|1001415199516254208|2018-05-29 10:49:23|2018-05-29 10:50:00|2705.22|0.001656133860550514 |0.0022112435484160416|2018      |10        |2018    |10      |\n",
      "|1001417880116891650|2018-05-29 11:00:02|2018-05-29 11:00:00|2698.87|0.0019272309432976154|0.0020400066064023476|2018      |11        |2018    |11      |\n",
      "|1001420270094168064|2018-05-29 11:09:32|2018-05-29 11:10:00|2701.13|0.0017407643404526263|0.0031069847934639756|2018      |11        |2018    |11      |\n",
      "|1001424695126880258|2018-05-29 11:27:07|2018-05-29 11:25:00|2700.56|0.002210637898972629 |0.002807087341143202 |2018      |11        |2018    |11      |\n",
      "|1001455721588969472|2018-05-29 13:30:24|2018-05-29 13:30:00|2682.05|0.0018390545052083933|0.003071718135565342 |2018      |13        |2018    |13      |\n",
      "|1001807174249713664|2018-05-30 12:46:57|2018-05-30 12:45:00|2721.15|8.362739852883948E-4 |0.0013075401579683982|2018      |12        |2018    |12      |\n",
      "|1001807204519997442|2018-05-30 12:47:04|2018-05-30 12:45:00|2721.15|8.362739852883948E-4 |0.0013075401579683982|2018      |12        |2018    |12      |\n",
      "|1001807216297627648|2018-05-30 12:47:07|2018-05-30 12:45:00|2721.15|8.362739852883948E-4 |0.0013075401579683982|2018      |12        |2018    |12      |\n",
      "+-------------------+-------------------+-------------------+-------+---------------------+---------------------+----------+----------+--------+--------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PART C. Match tweets to nearest SPX bar within ±10 minutes\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "# In this cell what I’m basically doing is aligning each tweet with the closest\n",
    "# SPX 5-minute bar within a +-10 minute window.\n",
    "#\n",
    "# I rename some overlapping columns on both the tweets side and the SPX side to avoid name collisions after the join\n",
    "#\n",
    "# I join tweets and SPX bars on the same calendar day using the date\n",
    "# part of `tweet_time` and `bar_time`. At this stage, each tweet is matched\n",
    "# with *all* SPX bars from that day.\n",
    "#\n",
    "# Step 3: For every tweet–bar pair, I compute the absolute time difference\n",
    "# in seconds between `tweet_time` and `bar_time`, and I only keep those pairs\n",
    "# where the difference is within ±10 minutes (<= 600 seconds). This trims\n",
    "# out bars that are clearly too far from the tweet.\n",
    "#\n",
    "# Step 4: Among the remaining candidates, I use a window partitioned by tweet\n",
    "# `id` and ordered by `time_diff_sec`, then keep only the row with rank 1.\n",
    "# This gives me a single nearest SPX bar for each tweet inside the time window.\n",
    "#\n",
    "# Step 5: I rename `bar_time` to `event_time` for clarity, since this is the\n",
    "# timestamp I’ll treat as the “event bar” in the later modeling. Finally, I\n",
    "# count how many tweets survived this matching step and throw an error if\n",
    "# nothing matched, so I don’t accidentally train on an empty dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To avoid column name collisions, rename year/hour on both sides\n",
    "tweets_for_join = (\n",
    "    tweets\n",
    "    .withColumnRenamed(\"year\", \"tweet_year\")\n",
    "    .withColumnRenamed(\"hour\", \"tweet_hour\")\n",
    ")\n",
    "\n",
    "spx_for_join = (\n",
    "    spx_rv\n",
    "    .withColumnRenamed(\"year\", \"spx_year\")\n",
    "    .withColumnRenamed(\"hour\", \"spx_hour\")\n",
    ")\n",
    "\n",
    "# 4.1 Join tweets with SPX on the same calendar day\n",
    "joined = (\n",
    "    tweets_for_join\n",
    "    .join(\n",
    "        spx_for_join,\n",
    "        F.to_date(\"tweet_time\") == F.to_date(\"bar_time\"),\n",
    "        \"inner\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4.2 Compute absolute time difference (in seconds) between tweet_time and bar_time\n",
    "joined = joined.withColumn(\n",
    "    \"time_diff_sec\",\n",
    "    F.abs(F.unix_timestamp(\"bar_time\") - F.unix_timestamp(\"tweet_time\"))\n",
    ")\n",
    "\n",
    "# 4.3 Keep only bars within ±10 minutes of the tweet\n",
    "window_secs = 600  # ±10 minutes\n",
    "joined_window = joined.filter(F.col(\"time_diff_sec\") <= window_secs)\n",
    "\n",
    "# 4.4 For each tweet, keep only the single nearest bar\n",
    "w_nearest = Window.partitionBy(\"id\").orderBy(\"time_diff_sec\")\n",
    "\n",
    "events = (\n",
    "    joined_window\n",
    "    .withColumn(\"rn\", F.row_number().over(w_nearest))\n",
    "    .filter(F.col(\"rn\") == 1)\n",
    "    .drop(\"rn\", \"time_diff_sec\")\n",
    ")\n",
    "\n",
    "# Rename bar_time to event_time for clarity\n",
    "events = events.withColumnRenamed(\"bar_time\", \"event_time\")\n",
    "\n",
    "print(\"Events rows (tweets used in pipeline):\", events.count())\n",
    "events.select(\n",
    "    \"id\", \"tweet_time\", \"event_time\",\n",
    "    \"Close\", \"rv_pre_30m\", \"rv_post_30m\",\n",
    "    \"tweet_year\", \"tweet_hour\", \"spx_year\", \"spx_hour\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "if events.count() == 0:\n",
    "    raise ValueError(\"No matched events within ±10 minutes. Check data ranges or window size.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shock threshold (90% quantile of rv_post_30m): 0.0028990257946355995\n",
      "Shock class distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|is_shock|count|\n",
      "+--------+-----+\n",
      "|       1| 1087|\n",
      "|       0| 9783|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----+-----------------------------------------+----------------------------------------------------+---------+---------+--------------------------+--------------------+----------------------+---------+--------+--------+----------+---------------------+-------+----------+---+\n",
      "|is_shock|         event_time|year|                                 category|                                       blue_category|sentiment|intensity|has_market_action_keywords|during_trading_hours|towards_ceo_or_company|favorites|retweets|text_len|num_exclam|           rv_pre_30m|  Close|tweet_hour|doy|\n",
      "+--------+-------------------+----+-----------------------------------------+----------------------------------------------------+---------+---------+--------------------------+--------------------+----------------------+---------+--------+--------+----------+---------------------+-------+----------+---+\n",
      "|       0|2018-05-29 10:05:00|2018|     Campaign / Rally / Election Politics|                       Immigration / Border Security| Negative|   Medium|                     False|                True|                 False|    88312|   23260|     277|         1|0.0019230080247938965|2709.29|        10|  3|\n",
      "|       0|2018-05-29 10:30:00|2018|Defense, Military, Sanctions, Geopolitics|            Foreign Policy / Geopolitics / Diplomacy| Positive|   Medium|                     False|                True|                 False|    63540|   13458|     245|         1|0.0012550933708381099|2704.19|        10|  3|\n",
      "|       0|2018-05-29 10:50:00|2018|     Campaign / Rally / Election Politics|Campaign / Elections / Rallies / Political Messaging| Negative|   Medium|                     False|                True|                 False|    64442|   16115|     278|         0| 0.001656133860550514|2705.22|        10|  3|\n",
      "|       0|2018-05-29 11:00:00|2018|     Campaign / Rally / Election Politics|Campaign / Elections / Rallies / Political Messaging| Negative|     High|                     False|                True|                 False|    83557|   18827|     277|         2|0.0019272309432976154|2698.87|        11|  3|\n",
      "|       1|2018-05-29 11:10:00|2018|     Campaign / Rally / Election Politics|Campaign / Elections / Rallies / Political Messaging| Negative|     High|                     False|                True|                 False|    67370|   14586|     230|         2|0.0017407643404526263|2701.13|        11|  3|\n",
      "+--------+-------------------+----+-----------------------------------------+----------------------------------------------------+---------+---------+--------------------------+--------------------+----------------------+---------+--------+--------+----------+---------------------+-------+----------+---+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PART D. Build shock label (is_shock) and ML dataframe\n",
    "# ==================================================\n",
    "\n",
    "# 5.1 Only consider rows where rv_post_30m exists\n",
    "non_null_events = events.where(F.col(\"rv_post_30m\").isNotNull())\n",
    "if non_null_events.count() == 0:\n",
    "    raise ValueError(\"No non-null rv_post_30m values; cannot build shock label.\")\n",
    "\n",
    "# 5.2 Use 90% quantile of rv_post_30m as shock threshold (more shocks than 95%)\n",
    "shock_quantile = 0.90\n",
    "quantiles = non_null_events.approxQuantile(\"rv_post_30m\", [shock_quantile], 0.0)\n",
    "threshold = float(quantiles[0])\n",
    "print(f\"Shock threshold ({int(shock_quantile*100)}% quantile of rv_post_30m):\", threshold)\n",
    "\n",
    "# 5.3 Define binary label: is_shock = 1 if rv_post_30m > threshold\n",
    "labeled = events.withColumn(\n",
    "    \"is_shock\",\n",
    "    (F.col(\"rv_post_30m\") > F.lit(threshold)).cast(T.IntegerType())\n",
    ")\n",
    "\n",
    "# 5.4 Categorical and numeric feature columns\n",
    "cat_cols = [\n",
    "    \"category\",\n",
    "    \"blue_category\",\n",
    "    \"sentiment\",\n",
    "    \"intensity\",\n",
    "    \"has_market_action_keywords\",\n",
    "    \"during_trading_hours\",\n",
    "    \"towards_ceo_or_company\",\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    \"favorites\",\n",
    "    \"retweets\",\n",
    "    \"text_len\",\n",
    "    \"num_exclam\",\n",
    "    \"rv_pre_30m\",\n",
    "    \"Close\",\n",
    "    \"tweet_hour\",\n",
    "    \"doy\",\n",
    "]\n",
    "\n",
    "# Day-of-week as a simple time feature\n",
    "labeled = labeled.withColumn(\"doy\", F.dayofweek(\"tweet_time\"))\n",
    "\n",
    "# 5.5 Build final ML dataframe\n",
    "ml_df = labeled.select(\n",
    "    \"is_shock\", \"event_time\", \"tweet_year\", *cat_cols, *num_cols\n",
    ").withColumnRenamed(\"tweet_year\", \"year\")\n",
    "\n",
    "print(\"Shock class distribution:\")\n",
    "ml_df.groupBy(\"is_shock\").count().show()\n",
    "\n",
    "ml_df.show(5, truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After NULL cleaning, any NULL in numeric cols?\n",
      "favorites: 0 NULLs\n",
      "retweets: 0 NULLs\n",
      "text_len: 0 NULLs\n",
      "num_exclam: 0 NULLs\n",
      "rv_pre_30m: 0 NULLs\n",
      "Close: 0 NULLs\n",
      "tweet_hour: 0 NULLs\n",
      "doy: 0 NULLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 7704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows: 3166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/04 17:49:00 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GBT sample predictions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/04 17:49:44 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+----------------------------------------+----------+\n",
      "|event_time         |is_shock|probability                             |prediction|\n",
      "+-------------------+--------+----------------------------------------+----------+\n",
      "|2009-06-30 13:35:00|0       |[0.9044880790851014,0.09551192091489857]|0.0       |\n",
      "|2009-07-28 15:50:00|0       |[0.810774500929421,0.18922549907057895] |0.0       |\n",
      "|2009-08-11 14:50:00|0       |[0.9321156042164586,0.06788439578354144]|0.0       |\n",
      "|2009-08-14 14:35:00|0       |[0.8519157424649585,0.1480842575350415] |0.0       |\n",
      "|2009-09-14 15:50:00|0       |[0.852829543817516,0.14717045618248403] |0.0       |\n",
      "|2009-10-05 14:40:00|0       |[0.7534886013839786,0.24651139861602145]|0.0       |\n",
      "|2009-10-14 14:15:00|0       |[0.7521372489758473,0.24786275102415267]|0.0       |\n",
      "|2010-03-31 13:40:00|0       |[0.9415470637678413,0.05845293623215875]|0.0       |\n",
      "|2010-04-06 14:35:00|0       |[0.9129256092935111,0.08707439070648892]|0.0       |\n",
      "|2010-04-16 15:55:00|0       |[0.7521372489758473,0.24786275102415267]|0.0       |\n",
      "+-------------------+--------+----------------------------------------+----------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1321:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression sample predictions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1332:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-----------------------------------------+----------+\n",
      "|event_time         |is_shock|probability                              |prediction|\n",
      "+-------------------+--------+-----------------------------------------+----------+\n",
      "|2009-06-30 13:35:00|0       |[0.9621662237900255,0.03783377620997452] |0.0       |\n",
      "|2009-07-28 15:50:00|0       |[0.8714417149827358,0.12855828501726418] |0.0       |\n",
      "|2009-08-11 14:50:00|0       |[0.9539380340084452,0.046061965991554765]|0.0       |\n",
      "|2009-08-14 14:35:00|0       |[0.9142697932132346,0.08573020678676535] |0.0       |\n",
      "|2009-09-14 15:50:00|0       |[0.9538459128418048,0.046154087158195245]|0.0       |\n",
      "|2009-10-05 14:40:00|0       |[0.9669801641980873,0.0330198358019127]  |0.0       |\n",
      "|2009-10-14 14:15:00|0       |[0.9560894130978992,0.04391058690210081] |0.0       |\n",
      "|2010-03-31 13:40:00|0       |[0.9779721582785278,0.022027841721472208]|0.0       |\n",
      "|2010-04-06 14:35:00|0       |[0.9603001258033964,0.03969987419660359] |0.0       |\n",
      "|2010-04-16 15:55:00|0       |[0.8986548956668798,0.10134510433312016] |0.0       |\n",
      "+-------------------+--------+-----------------------------------------+----------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PART E. ML pipeline: StringIndexer + OneHotEncoder + GBT\n",
    "# ==================================================\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier, LogisticRegression\n",
    "\n",
    "# 6.0 Clean NULLs in numeric features to avoid VectorAssembler errors\n",
    "# We simply fill numeric NULLs with 0.0 (you can choose a different strategy if desired).\n",
    "ml_df_clean = ml_df\n",
    "for c in num_cols:\n",
    "    ml_df_clean = ml_df_clean.withColumn(c, F.coalesce(F.col(c), F.lit(0.0)))\n",
    "\n",
    "print(\"After NULL cleaning, any NULL in numeric cols?\")\n",
    "for c in num_cols:\n",
    "    null_cnt = ml_df_clean.filter(F.col(c).isNull()).count()\n",
    "    print(f\"{c}: {null_cnt} NULLs\")\n",
    "\n",
    "# 6.1 Train/test split (random split; could also split by year)\n",
    "train, test = ml_df_clean.randomSplit([0.7, 0.3], seed=42)\n",
    "if test.count() == 0:\n",
    "    test = train\n",
    "\n",
    "print(\"Train rows:\", train.count())\n",
    "print(\"Test rows:\",  test.count())\n",
    "\n",
    "stages_common = []\n",
    "\n",
    "# 6.2 Encode categorical columns (shared by both models)\n",
    "for c in cat_cols:\n",
    "    idx_col = c + \"_idx\"\n",
    "    oh_col = c + \"_oh\"\n",
    "\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=c,\n",
    "        outputCol=idx_col,\n",
    "        handleInvalid=\"keep\"   # unseen or null categories go to a special bucket\n",
    "    )\n",
    "\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCol=idx_col,\n",
    "        outputCol=oh_col\n",
    "    )\n",
    "\n",
    "    stages_common += [indexer, encoder]\n",
    "\n",
    "# 6.3 Assemble all features into a single vector\n",
    "feature_cols = [c + \"_oh\" for c in cat_cols] + num_cols\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"   # if any unexpected NULL sneaks in, keep instead of error\n",
    ")\n",
    "stages_common.append(assembler)\n",
    "\n",
    "# ==================================================\n",
    "# 6.4 Model 1: Gradient-Boosted Trees (GBT)\n",
    "# ==================================================\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"is_shock\",\n",
    "    featuresCol=\"features\",\n",
    "    maxDepth=3,\n",
    "    maxIter=20,\n",
    ")\n",
    "\n",
    "gbt_pipeline = Pipeline(stages=stages_common + [gbt])\n",
    "\n",
    "gbt_model = gbt_pipeline.fit(train)\n",
    "gbt_pred = gbt_model.transform(test)\n",
    "\n",
    "print(\"=== GBT sample predictions ===\")\n",
    "gbt_pred.select(\"event_time\", \"is_shock\", \"probability\", \"prediction\") \\\n",
    "        .show(10, truncate=False)\n",
    "\n",
    "# ==================================================\n",
    "# 6.5 Model 2: Logistic Regression (baseline linear model)\n",
    "# ==================================================\n",
    "\n",
    "# We can reuse the same preprocessing stages (indexer + OHE + assembler),\n",
    "# but need a fresh pipeline object to attach LogisticRegression at the end.\n",
    "lr = LogisticRegression(\n",
    "    labelCol=\"is_shock\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=50,\n",
    "    regParam=0.0,      # you can tune regularization if needed\n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "lr_pipeline = Pipeline(stages=stages_common + [lr])\n",
    "\n",
    "lr_model = lr_pipeline.fit(train)\n",
    "lr_pred = lr_model.transform(test)\n",
    "\n",
    "print(\"=== Logistic Regression sample predictions ===\")\n",
    "lr_pred.select(\"event_time\", \"is_shock\", \"probability\", \"prediction\") \\\n",
    "       .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GBT] PR-AUC:  0.7138\n",
      "[GBT] ROC-AUC: 0.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1483:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR ] PR-AUC:  0.6498\n",
      "[LR ] ROC-AUC: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PART F. Evaluation metrics (PR-AUC and ROC-AUC)\n",
    "# ==================================================\n",
    "\n",
    "if test.select(\"is_shock\").distinct().count() > 1:\n",
    "    evaluator_pr = BinaryClassificationEvaluator(\n",
    "        labelCol=\"is_shock\",\n",
    "        rawPredictionCol=\"rawPrediction\",\n",
    "        metricName=\"areaUnderPR\"\n",
    "    )\n",
    "    evaluator_roc = BinaryClassificationEvaluator(\n",
    "        labelCol=\"is_shock\",\n",
    "        rawPredictionCol=\"rawPrediction\",\n",
    "        metricName=\"areaUnderROC\"\n",
    "    )\n",
    "\n",
    "    # Evaluate GBT\n",
    "    gbt_pr_auc = evaluator_pr.evaluate(gbt_pred)\n",
    "    gbt_roc_auc = evaluator_roc.evaluate(gbt_pred)\n",
    "    print(f\"[GBT] PR-AUC:  {gbt_pr_auc:.4f}\")\n",
    "    print(f\"[GBT] ROC-AUC: {gbt_roc_auc:.4f}\")\n",
    "\n",
    "    # Evaluate Logistic Regression\n",
    "    lr_pr_auc = evaluator_pr.evaluate(lr_pred)\n",
    "    lr_roc_auc = evaluator_roc.evaluate(lr_pred)\n",
    "    print(f\"[LR ] PR-AUC:  {lr_pr_auc:.4f}\")\n",
    "    print(f\"[LR ] ROC-AUC: {lr_roc_auc:.4f}\")\n",
    "else:\n",
    "    print(\"Test set has only one class label; PR/ROC evaluation is not meaningful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT model saved to: /storage/work/yfl5682/Project/models/gbt_model\n",
      "Logistic Regression model saved to: /storage/work/yfl5682/Project/models/lr_model\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Save models\n",
    "# ==================================================\n",
    "\n",
    "model_dir = \"/storage/work/yfl5682/Project/models\"\n",
    "\n",
    "# Save GBT model\n",
    "gbt_save_path = f\"{model_dir}/gbt_model\"\n",
    "gbt_model.write().overwrite().save(gbt_save_path)\n",
    "print(f\"GBT model saved to: {gbt_save_path}\")\n",
    "\n",
    "# Save Logistic Regression model\n",
    "lr_save_path  = f\"{model_dir}/lr_model\"\n",
    "lr_model.write().overwrite().save(lr_save_path)\n",
    "print(f\"Logistic Regression model saved to: {lr_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix: GBT ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 2798  |\n",
      "| False Positive  | 40    |\n",
      "| False Negative  | 162   |\n",
      "| True Positive   | 166   |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 2797  |\n",
      "| False Positive  | 41    |\n",
      "| False Negative  | 192   |\n",
      "| True Positive   | 136   |\n",
      "+-----------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2797, 41, 192, 136)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_confusion_matrix(pred_df):\n",
    "    \"\"\"\n",
    "    pred_df must contain columns:\n",
    "        - prediction (0/1)\n",
    "        - is_shock (0/1)\n",
    "    \"\"\"\n",
    "    cm = (\n",
    "        pred_df\n",
    "        .select(\n",
    "            F.col(\"is_shock\").cast(\"int\"),\n",
    "            F.col(\"prediction\").cast(\"int\")\n",
    "        )\n",
    "        .groupBy(\"is_shock\", \"prediction\")\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    # Initialize counts = 0 for missing cells\n",
    "    def get_val(df, a, b):\n",
    "        row = df.filter((F.col(\"is_shock\") == a) & (F.col(\"prediction\") == b)).select(\"count\").collect()\n",
    "        return row[0][0] if row else 0\n",
    "\n",
    "    cm_local = cm.collect()  # bring small aggregated results to driver\n",
    "\n",
    "    # Extract confusion matrix elements\n",
    "    TN = get_val(cm, 0, 0)\n",
    "    FP = get_val(cm, 0, 1)\n",
    "    FN = get_val(cm, 1, 0)\n",
    "    TP = get_val(cm, 1, 1)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"+-----------------+-------+\")\n",
    "    print(f\"| True Negative   | {TN:<5} |\")\n",
    "    print(f\"| False Positive  | {FP:<5} |\")\n",
    "    print(f\"| False Negative  | {FN:<5} |\")\n",
    "    print(f\"| True Positive   | {TP:<5} |\")\n",
    "    print(\"+-----------------+-------+\")\n",
    "    \n",
    "    return TN, FP, FN, TP\n",
    "\n",
    "\n",
    "print(\"=== Confusion Matrix: GBT ===\")\n",
    "compute_confusion_matrix(gbt_pred)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix: Logistic Regression ===\")\n",
    "compute_confusion_matrix(lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix: GBT (Intensity = High) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 348   |\n",
      "| False Positive  | 5     |\n",
      "| False Negative  | 28    |\n",
      "| True Positive   | 33    |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: Logistic Regression (Intensity = High) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 347   |\n",
      "| False Positive  | 6     |\n",
      "| False Negative  | 37    |\n",
      "| True Positive   | 24    |\n",
      "+-----------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(347, 6, 37, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter intensity = High\n",
    "gbt_high = gbt_pred.filter(F.col(\"intensity\") == \"High\")\n",
    "lr_high  = lr_pred.filter(F.col(\"intensity\") == \"High\")\n",
    "\n",
    "# GBT confusion matrix (High only)\n",
    "print(\"=== Confusion Matrix: GBT (Intensity = High) ===\")\n",
    "compute_confusion_matrix(gbt_high)\n",
    "\n",
    "# LR confusion matrix (High only)\n",
    "print(\"\\n=== Confusion Matrix: Logistic Regression (Intensity = High) ===\")\n",
    "compute_confusion_matrix(lr_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix: GBT (towards_ceo_or_company = True) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 723   |\n",
      "| False Positive  | 13    |\n",
      "| False Negative  | 30    |\n",
      "| True Positive   | 30    |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: LR (towards_ceo_or_company = True) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 723   |\n",
      "| False Positive  | 13    |\n",
      "| False Negative  | 37    |\n",
      "| True Positive   | 23    |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: GBT (has_market_action_keywords = True) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 45    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 2     |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: LR (has_market_action_keywords = True) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2440:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 46    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 3     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46, 0, 3, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Filter subsets ---\n",
    "gbt_ceo  = gbt_pred.filter(F.col(\"towards_ceo_or_company\") == True)\n",
    "lr_ceo   = lr_pred.filter(F.col(\"towards_ceo_or_company\") == True)\n",
    "\n",
    "gbt_keywords = gbt_pred.filter(F.col(\"has_market_action_keywords\") == True)\n",
    "lr_keywords  = lr_pred.filter(F.col(\"has_market_action_keywords\") == True)\n",
    "\n",
    "# --- CEO-directed tweets ---\n",
    "print(\"=== Confusion Matrix: GBT (towards_ceo_or_company = True) ===\")\n",
    "compute_confusion_matrix(gbt_ceo)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix: LR (towards_ceo_or_company = True) ===\")\n",
    "compute_confusion_matrix(lr_ceo)\n",
    "\n",
    "# --- Tweets with market-action keywords ---\n",
    "print(\"\\n=== Confusion Matrix: GBT (has_market_action_keywords = True) ===\")\n",
    "compute_confusion_matrix(gbt_keywords)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix: LR (has_market_action_keywords = True) ===\")\n",
    "compute_confusion_matrix(lr_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found categories: ['uncategorized', 'Social, Personal, or Non-Policy Content', 'Personal, Social, or Non-Policy Content', 'Macroeconomics & Monetary Policies', 'macroeconomics', 'Regulation', 'energy', 'macro', 'campaign', 'Social', 'macroeconomics & Monetary Policies', 'Energy, Oil & Gas, Renewables', 'social', 'Defense, Military, Sanctions, Geopolitics', 'macroeconomics & monetary policies', 'trade', 'defense', 'Uncategorized', 'Campaign / Rally / Election Politics', 'Trade Policy & Industrial / Manufacturing', 'regulation', 'Regulation, Antitrust, Legal Actions', None]\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: uncategorized ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 44    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 2     |\n",
      "| True Positive   | 5     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 44    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 2     |\n",
      "| True Positive   | 5     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Social, Personal, or Non-Policy Content ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2803:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 14    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2895:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 14    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Personal, Social, or Non-Policy Content ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 670   |\n",
      "| False Positive  | 6     |\n",
      "| False Negative  | 26    |\n",
      "| True Positive   | 19    |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 675   |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 35    |\n",
      "| True Positive   | 10    |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Macroeconomics & Monetary Policies ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 179   |\n",
      "| False Positive  | 3     |\n",
      "| False Negative  | 15    |\n",
      "| True Positive   | 16    |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 179   |\n",
      "| False Positive  | 3     |\n",
      "| False Negative  | 18    |\n",
      "| True Positive   | 13    |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: macroeconomics ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3493:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 1     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3585:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 1     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Regulation ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 0     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 0     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: energy ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 23    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 22    |\n",
      "| False Positive  | 2     |\n",
      "| False Negative  | 2     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: macro ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 7     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 2     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 7     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: campaign ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 214   |\n",
      "| False Positive  | 6     |\n",
      "| False Negative  | 12    |\n",
      "| True Positive   | 23    |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 211   |\n",
      "| False Positive  | 9     |\n",
      "| False Negative  | 17    |\n",
      "| True Positive   | 18    |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Social ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 24    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4695:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 24    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: macroeconomics & Monetary Policies ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4813:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 0     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 0     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Energy, Oil & Gas, Renewables ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 19    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 19    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: social ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 156   |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 8     |\n",
      "| True Positive   | 8     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 154   |\n",
      "| False Positive  | 3     |\n",
      "| False Negative  | 8     |\n",
      "| True Positive   | 8     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Defense, Military, Sanctions, Geopolitics ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 173   |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 8     |\n",
      "| True Positive   | 11    |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 173   |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 9     |\n",
      "| True Positive   | 10    |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: macroeconomics & monetary policies ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 4     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 4     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: trade ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 48    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 4     |\n",
      "| True Positive   | 8     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 47    |\n",
      "| False Positive  | 2     |\n",
      "| False Negative  | 3     |\n",
      "| True Positive   | 9     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: defense ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 127   |\n",
      "| False Positive  | 4     |\n",
      "| False Negative  | 9     |\n",
      "| True Positive   | 20    |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 128   |\n",
      "| False Positive  | 3     |\n",
      "| False Negative  | 12    |\n",
      "| True Positive   | 17    |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Uncategorized ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 43    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 1     |\n",
      "| True Positive   | 4     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 43    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 5     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Campaign / Rally / Election Politics ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 823   |\n",
      "| False Positive  | 11    |\n",
      "| False Negative  | 63    |\n",
      "| True Positive   | 39    |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 821   |\n",
      "| False Positive  | 13    |\n",
      "| False Negative  | 69    |\n",
      "| True Positive   | 33    |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Trade Policy & Industrial / Manufacturing ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 61    |\n",
      "| False Positive  | 2     |\n",
      "| False Negative  | 4     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 62    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 4     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: regulation ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 88    |\n",
      "| False Positive  | 2     |\n",
      "| False Negative  | 3     |\n",
      "| True Positive   | 6     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 89    |\n",
      "| False Positive  | 1     |\n",
      "| False Negative  | 5     |\n",
      "| True Positive   | 4     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: Regulation, Antitrust, Legal Actions ===\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 80    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 5     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "--- Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 80    |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 5     |\n",
      "| True Positive   | 1     |\n",
      "+-----------------+-------+\n",
      "\n",
      "==============================================\n",
      "=== Confusion Matrix for Category: None ===\n",
      "==============================================\n",
      "No rows found for category: None\n"
     ]
    }
   ],
   "source": [
    "# 1. Get distinct categories from the dataset\n",
    "categories = [row[0] for row in ml_df.select(\"category\").distinct().collect()]\n",
    "\n",
    "print(\"Found categories:\", categories)\n",
    "\n",
    "# 2. Loop through each category and compute confusion matrices\n",
    "for cat in categories:\n",
    "    print(\"\\n==============================================\")\n",
    "    print(f\"=== Confusion Matrix for Category: {cat} ===\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    # Filter predictions for this category\n",
    "    gbt_cat = gbt_pred.filter(F.col(\"category\") == cat)\n",
    "    lr_cat  = lr_pred.filter(F.col(\"category\") == cat)\n",
    "\n",
    "    # Avoid empty category subsets\n",
    "    if gbt_cat.count() == 0:\n",
    "        print(f\"No rows found for category: {cat}\")\n",
    "        continue\n",
    "\n",
    "    # GBT confusion matrix\n",
    "    print(\"\\n--- GBT ---\")\n",
    "    compute_confusion_matrix(gbt_cat)\n",
    "\n",
    "    # LR confusion matrix\n",
    "    print(\"\\n--- Logistic Regression ---\")\n",
    "    compute_confusion_matrix(lr_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix: GBT (Intensity = High) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 1306  |\n",
      "| False Positive  | 14    |\n",
      "| False Negative  | 60    |\n",
      "| True Positive   | 68    |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: Logistic Regression (Intensity = High) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 0     |\n",
      "| False Positive  | 0     |\n",
      "| False Negative  | 0     |\n",
      "| True Positive   | 0     |\n",
      "+-----------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter intensity = High\n",
    "gbt_high = gbt_pred.filter(F.col(\"sentiment\") == \"Positive\")\n",
    "lr_high  = lr_pred.filter(F.col(\"sentiment\") == \"Positie\")\n",
    "\n",
    "# GBT confusion matrix (High only)\n",
    "print(\"=== Confusion Matrix: GBT (Intensity = High) ===\")\n",
    "compute_confusion_matrix(gbt_high)\n",
    "\n",
    "# LR confusion matrix (High only)\n",
    "print(\"\\n=== Confusion Matrix: Logistic Regression (Intensity = High) ===\")\n",
    "compute_confusion_matrix(lr_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix: GBT (Intensity = High) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 1009  |\n",
      "| False Positive  | 18    |\n",
      "| False Negative  | 68    |\n",
      "| True Positive   | 70    |\n",
      "+-----------------+-------+\n",
      "\n",
      "=== Confusion Matrix: Logistic Regression (Intensity = High) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "+-----------------+-------+\n",
      "| True Negative   | 1007  |\n",
      "| False Positive  | 20    |\n",
      "| False Negative  | 81    |\n",
      "| True Positive   | 57    |\n",
      "+-----------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1007, 20, 81, 57)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter intensity = High\n",
    "gbt_high = gbt_pred.filter(F.col(\"sentiment\") == \"Negative\")\n",
    "lr_high  = lr_pred.filter(F.col(\"sentiment\") == \"Negative\")\n",
    "\n",
    "# GBT confusion matrix (High only)\n",
    "print(\"=== Confusion Matrix: GBT (Intensity = High) ===\")\n",
    "compute_confusion_matrix(gbt_high)\n",
    "\n",
    "# LR confusion matrix (High only)\n",
    "print(\"\\n=== Confusion Matrix: Logistic Regression (Intensity = High) ===\")\n",
    "compute_confusion_matrix(lr_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds410_f25)",
   "language": "python",
   "name": "ds410_f25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
